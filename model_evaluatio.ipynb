{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "252ad178",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18da2dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Given the following confusion matrix, evaluate \n",
    "#(by hand) the model's performance.\n",
    "#In the context of this problem, what is a false positive?\n",
    "## the model predicting dog when the actual is a cat\n",
    "#In the context of this problem, what is a false negative?\n",
    "#the model predicting cat when it's actually a dog\n",
    "#How would you describe this model?\n",
    "#you can say its looking for dogs or cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d42c2048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>model1</th>\n",
       "      <th>model2</th>\n",
       "      <th>model3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>No Defect</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      actual     model1  model2     model3\n",
       "0  No Defect  No Defect  Defect  No Defect"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('c3.csv').head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd8a858c",
   "metadata": {},
   "outputs": [],
   "source": [
    "c3 = pd.read_csv('c3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c23809fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#An internal team wants to investigate the cause of the \n",
    "#manufacturing defects. \n",
    "#They tell you that they want to identify as many of t\n",
    "#he ducks that have a defect as possible. \n",
    "#Which evaluation metric would be appropriate here? \n",
    "## the model with the highest specificity will be the model that\n",
    "## more accurately predicts negative outcomes\n",
    "## but we didn't really learn that one so I'm going to use precision \n",
    "## and us defect as my positive value\n",
    "#Which model would be the best fit for this use case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7c293c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  8,   2],\n",
       "       [  8, 182]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(c3.model1,c3.actual, labels = ('Defect','No Defect'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "59c95b97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  9,  81],\n",
       "       [  7, 103]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(c3.model2,c3.actual, labels = ('Defect','No Defect'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d795de3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13, 86],\n",
       "       [ 3, 98]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(c3.model3,c3.actual, labels = ('Defect','No Defect'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669320a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_specific():\n",
    "    ''' get specific takes in a confusion matrix and tells you the specificy value'''\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b111dd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset1 = c3[c3.model1 == 'Defect']\n",
    "subset2 = c3[c3.model2 == 'Defect']\n",
    "subset3 = c3[c3.model3 == 'Defect']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a061f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_precision= (subset1.model1 == subset1.actual).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5d892de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_precision= (subset2.model2 == subset2.actual).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b6c1ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3_precision= (subset3.model3 == subset3.actual).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea085242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model1 defect precision: 80.00%\n",
      "Model2 defect precision: 10.00%\n",
      "Model3 defect precision: 13.13%\n"
     ]
    }
   ],
   "source": [
    "# using the % to cast a float to a percentage\n",
    "print(f'Model1 defect precision: {model1_precision:.2%}')\n",
    "print(f'Model2 defect precision: {model2_precision:.2%}')\n",
    "print(f'Model3 defect precision: {model3_precision:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b86deb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we're gonna want to use model 1 for this purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e1035e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#They need you to predict which ducks will have defects, \n",
    "#but tell you the really don't want to accidentally give out a vacation package when the duck really doesn't have a defect. Which evaluation metric would be appropriate here? \n",
    "#Which model would be the best fit for this use case?\n",
    "#precision again based on defect, going to want to use model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1d4c753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>model1</th>\n",
       "      <th>model2</th>\n",
       "      <th>model3</th>\n",
       "      <th>model4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  actual model1 model2 model3 model4\n",
       "0    cat    cat    dog    cat    dog"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Given this dataset, use pandas to create a baseline model \n",
    "#(i.e. a model that just predicts the most common class) \n",
    "#and answer the following questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "daa816c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "paws = pd.read_csv('gives_you_paws.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5f439e0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    dog\n",
       "Name: actual, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paws.actual.mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8f28ebf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "paws['baseline'] = 'dog'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "973cef00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>model1</th>\n",
       "      <th>model2</th>\n",
       "      <th>model3</th>\n",
       "      <th>model4</th>\n",
       "      <th>baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     actual model1 model2 model3 model4 baseline\n",
       "0       cat    cat    dog    cat    dog      dog\n",
       "1       dog    dog    cat    cat    dog      dog\n",
       "2       dog    cat    cat    cat    dog      dog\n",
       "3       dog    dog    dog    cat    dog      dog\n",
       "4       cat    cat    cat    dog    dog      dog\n",
       "...     ...    ...    ...    ...    ...      ...\n",
       "4995    dog    dog    dog    dog    dog      dog\n",
       "4996    dog    dog    cat    cat    dog      dog\n",
       "4997    dog    cat    cat    dog    dog      dog\n",
       "4998    cat    cat    cat    cat    dog      dog\n",
       "4999    dog    dog    dog    dog    dog      dog\n",
       "\n",
       "[5000 rows x 6 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0a111f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In terms of accuracy, how do the various models compare to the \n",
    "#baseline model? \n",
    "#Are any of the models better than the baseline?\n",
    "## model 1 and model 4 are more accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6a6ff882",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_accuracy = (paws.baseline == paws.actual).mean()\n",
    "model1_accuracy = (paws.model1 == paws.actual).mean()\n",
    "model2_accuracy = (paws.model2 == paws.actual).mean()\n",
    "model3_accuracy = (paws.model3 == paws.actual).mean()\n",
    "model4_accuracy = (paws.model4 == paws.actual).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "082ae9b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline:65.08%\n",
      "model1:80.74%\n",
      "model2:63.04%\n",
      "model3:50.96%\n",
      "model4:74.26%\n"
     ]
    }
   ],
   "source": [
    "print(f'baseline:{baseline_accuracy:.2%}')\n",
    "print(f'model1:{model1_accuracy:.2%}')\n",
    "print(f'model2:{model2_accuracy:.2%}')\n",
    "print(f'model3:{model3_accuracy:.2%}')\n",
    "print(f'model4:{model4_accuracy:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32d0077",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Suppose you are working on a team that solely \n",
    "#deals with dog pictures. \n",
    "#Which of these models would you recommend?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c0f85068",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsetb = paws[paws.baseline == 'dog']\n",
    "baseline_precision = (subsetb.baseline == subsetb.actual).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1ddef26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsetm1 = paws[paws.model1 == 'dog']\n",
    "model1_precision = (subsetm1.model1 == subsetm1.actual).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cf04a8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsetm2 = paws[paws.model2 == 'dog']\n",
    "model2_precision = (subsetm2.model2 == subsetm2.actual).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9861c01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsetm3 = paws[paws.model3 == 'dog']\n",
    "model3_precision = (subsetm3.model3 == subsetm3.actual).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c41382a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsetm4 = paws[paws.model4 == 'dog']\n",
    "model4_precision = (subsetm4.model4 == subsetm4.actual).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ae998cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline:65.08%\n",
      "model1:89.00%\n",
      "model2:89.32%\n",
      "model3:65.99%\n",
      "model4:73.12%\n"
     ]
    }
   ],
   "source": [
    "print(f'baseline:{baseline_precision:.2%}')\n",
    "print(f'model1:{model1_precision:.2%}')\n",
    "print(f'model2:{model2_precision:.2%}')\n",
    "print(f'model3:{model3_precision:.2%}')\n",
    "print(f'model4:{model4_precision:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b73de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model 2 can pridict dogs the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8fd1992d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Suppose you are working on a team that solely \n",
    "#deals with cat pictures. \n",
    "#Which of these models would you recommend?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5c614acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = paws[paws.baseline == 'cat']\n",
    "baseline_cat_precision = (subset.baseline == subset.actual).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "39255f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = paws[paws.model1 == 'cat']\n",
    "model1_cat_precision = (subset.model1 == subset.actual).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fab08812",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = paws[paws.model2 == 'cat']\n",
    "model2_cat_precision = (subset.model2 == subset.actual).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c73e6d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = paws[paws.model3 == 'cat']\n",
    "model3_cat_precision = (subset.model3 == subset.actual).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "18d0006f",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = paws[paws.model4 == 'cat']\n",
    "model4_cat_precision = (subset.model4 == subset.actual).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d0aeee37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline:nan%\n",
      "model1:68.98%\n",
      "model2:48.41%\n",
      "model3:35.83%\n",
      "model4:80.72%\n"
     ]
    }
   ],
   "source": [
    "print(f'baseline:{baseline_cat_precision:.2%}')\n",
    "print(f'model1:{model1_cat_precision:.2%}')\n",
    "print(f'model2:{model2_cat_precision:.2%}')\n",
    "print(f'model3:{model3_cat_precision:.2%}')\n",
    "print(f'model4:{model4_cat_precision:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d6111f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model 4 will be best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0674a562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8074"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Follow the links below to read the documentation about each \n",
    "#function, then apply those functions to the data from the \n",
    "#previous problem.\n",
    "sklearn.metrics.accuracy_score(paws.model1,paws.actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "af0eaceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.803318992009834"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.precision_score(paws.model1,paws.actual, pos_label ='dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2daf92a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8150057273768614"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.precision_score(paws.model1,paws.actual, pos_label ='cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6161d82e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6897721764420747"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.recall_score(paws.model1,paws.actual, pos_label ='cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f6f9eebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         cat       0.82      0.69      0.75      2063\n",
      "         dog       0.80      0.89      0.84      2937\n",
      "\n",
      "    accuracy                           0.81      5000\n",
      "   macro avg       0.81      0.79      0.80      5000\n",
      "weighted avg       0.81      0.81      0.80      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.metrics.classification_report(paws.model1,paws.actual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "74c66625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         cat       0.89      0.48      0.63      3212\n",
      "         dog       0.49      0.89      0.63      1788\n",
      "\n",
      "    accuracy                           0.63      5000\n",
      "   macro avg       0.69      0.69      0.63      5000\n",
      "weighted avg       0.75      0.63      0.63      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.metrics.classification_report(paws.model2,paws.actual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef47bc6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
